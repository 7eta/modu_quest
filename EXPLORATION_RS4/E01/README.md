>## **루브릭**
>
>|번호|평가문항|상세기준|평가결과|
>|:---:|---|---|:---:|
>|1|프로젝트 1의 회귀모델 예측정확도가 기준 이상 높게 나왔는가?|MSE 손실함수값 3000 이하를 달성||
>|2|프로젝트 2의 회귀모델 예측정확도가 기준 이상 높게 나왔는가?|RMSE 값 150 이하를 달성|⭐|
>|3|시각화 요구사항이 정확하게 이루어졌는가?|각 프로젝트 진행 과정에서 요구하고 있는 데이터개수 시각화 및 예측결과 시각화를 모두 진행하였다.|⭐|

----------------------------------------------

- 코더 : 장승우
- 리뷰어 : 김경훈

----------------------------------------------

PRT(PeerReviewTemplate)

- [ ] 코드가 정상적으로 동작하고 주어진 문제를 해결했나요?

> 프로젝트 1에서 MSE 값이 3000이하로 떨어지지 않았습니다.

- [X] 주석을 보고 작성자의 코드가 이해되었나요?


- [ ] 코드가 에러를 유발할 가능성이 있나요?


- [X] 코드 작성자가 코드를 제대로 이해하고 작성했나요? (직접 인터뷰해보기)

- [X] 코드가 간결한가요?


----------------------------------------------

참고 링크 및 코드 개선

> 모든 기능을 함수로 짤거면 전역변수는 선언하지 않고 함수내에서 새로운 변수를 생성 후 리턴 하는것이 좋을 것 같습니다.
> Functional Programing 관점으로 보았을때 전역변수를 계속 수정하는것은 에러를 유발할 위험을 가지고 있다고 합니다.

``` python

def training(X, y, cnt=1000, learning_rate=0.1):
  
  W = np.random.rand(x_train.shape[1])
  b = np.random.rand()
  dW = 0
  db = 0
  
  for i in range(cnt):
    dW,db = gradient(X,W,b,y,dW,db)
    W -= learning_rate * dW
    b -= learning_rate * db
    L = loss(X,W,b,y)
    if i % 100 == 0:
      print(f'{i}, loss {L:.4f}')
  
  return W, b
  
W, b = training(x_train, y_train)
test_val(x_test, W, b, y_test)
```
